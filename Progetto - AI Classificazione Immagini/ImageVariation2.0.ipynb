{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo le librerie necessarie per il progetto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image,ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet152\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recupero il numero delle classi e verifico se la scheda video è impostata come device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n° Classi: 8\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "train_path = r'C:\\Users\\alessio\\Desktop\\Dimarco_Lomonaco_Salemi\\BACKREMOVING\\AI\\train'\n",
    "\n",
    "num_classes = len(os.listdir(train_path))\n",
    "print(\"n° Classi:\", num_classes)\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa funzione prende in input un percorso relativo ad un'immagine (image_path), una bounding box (bbox) che specifica la regione di interesse dell'immagine e  l'immagine presa col path viene ritagliata in base ai valori della bounding box e normalizzata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image_path, bbox):\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "    image_rgb = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    image_rgb = image_rgb[y_min:y_max, x_min:x_max]\n",
    "    res = cv2.resize(image_rgb, (282, 282))\n",
    "    res =np.array(res)/255.0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo codice legge un file CSV contenente informazioni sulle immagini come:path, bounding box e etichette. Successivamente, manda ciascuna immagine in elaborazione alla funzione precedete, dopo memorizza l'immagine elaborata e l'etichetta associata in liste separate per l'addestramento di un modello di machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "train_labels = []\n",
    "train_df = pd.read_csv('train.csv')\n",
    "for i, (imp, x_min, y_min, x_max, y_max, label) in train_df.iterrows():\n",
    "    image_path = os.path.join('AI/train', imp.replace('/', '\\\\'))\n",
    "    label = label\n",
    "    bbox=[x_min , y_min, x_max, y_max]\n",
    "    for i in range(len(bbox)):\n",
    "        if bbox[i] < 0:\n",
    "            bbox[i] = 0\n",
    "    image= crop(image_path,bbox)\n",
    "    image_path = os.path.join('AI/save', imp.replace('/', '\\\\'))\n",
    "    train_labels.append(label)\n",
    "    train_images.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo codice converte le immagini e le etichette del dataset in tensori PyTorch, necessari per l'addestramento di modelli di deep learning. Inoltre, riorganizza le dimensioni delle immagini per adattarle al formato comunemente utilizzato da PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: [0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "labels = list(set(train_labels))\n",
    "print(\"labels:\", labels)\n",
    "# Conversione delle immagini in tensori\n",
    "train_images_tensor = torch.from_numpy(train_images).permute(0, 3, 1, 2).float()\n",
    "train_labels_tensor = torch.from_numpy(train_labels).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imposto la batch size e creo il dataset di addestramento, di validazione e i data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as T\n",
    "from sklearn.model_selection import train_test_split\n",
    "batch_size = 32\n",
    "\n",
    "# Divisione dei dati in train e validation\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(train_images_tensor, train_labels_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creazione dei dataset\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "val_dataset = TensorDataset(X_val, Y_val)\n",
    "\n",
    "# Crea i data loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo modello si sulla trasformazione colorjitter, tale trasformazione aiuta il modello a generalizzare meglio poiche va a cambiare i colori all'interno dell'immagine inoltre viene fatto un crop a 224 per eliminare informazioni inutili dall'immagine e perche resnet lavora meglio con queste dimensioni.\n",
    "Inoltre i valori di contrasto e luminosità sono stati trovati in maniera manuale giocando con tali valori su software di manipolazioni di immagini, cercando di trovare dei valori che rendessero gli sfondi simili senza coprire l'obiettivo della predizione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=resnet152(weights=\"IMAGENET1K_V2\")\n",
    "transf = T.ColorJitter(brightness=(0.1),contrast=(2),saturation=2,hue=(-0.5,.5)),\n",
    "transform = T.Compose([\n",
    "    T.RandomApply(transf,0.75),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.CenterCrop(224)\n",
    "])\n",
    "criterion = nn.NLLLoss()\n",
    "# Modifica il classificatore finale del modello\n",
    "n_inputs = model.fc.in_features\n",
    "# Scongelamento dei pesi del modello in modo che possa imparare dai dati di training (vale sia per il classificatore che per tutti gli altri strati)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(n_inputs, num_classes),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "lr=0.00001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.0001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] Training Loss: 2.0452, Training Accuracy: 16.88%, Validation Loss: 1.9824, Validation Accuracy: 26.25%\n",
      "Epoch [2] Training Loss: 1.9238, Training Accuracy: 32.66%, Validation Loss: 1.8661, Validation Accuracy: 49.69%\n",
      "Epoch [3] Training Loss: 1.7094, Training Accuracy: 55.55%, Validation Loss: 1.5404, Validation Accuracy: 79.38%\n",
      "Epoch [4] Training Loss: 1.4278, Training Accuracy: 76.09%, Validation Loss: 1.2589, Validation Accuracy: 85.94%\n",
      "Epoch [5] Training Loss: 1.0760, Training Accuracy: 86.41%, Validation Loss: 0.8950, Validation Accuracy: 92.50%\n",
      "Epoch [6] Training Loss: 0.7332, Training Accuracy: 91.25%, Validation Loss: 0.5643, Validation Accuracy: 96.25%\n",
      "Epoch [7] Training Loss: 0.4562, Training Accuracy: 96.17%, Validation Loss: 0.5322, Validation Accuracy: 94.38%\n",
      "Epoch [8] Training Loss: 0.3261, Training Accuracy: 97.19%, Validation Loss: 0.2995, Validation Accuracy: 97.19%\n",
      "Epoch [9] Training Loss: 0.2304, Training Accuracy: 97.50%, Validation Loss: 0.4347, Validation Accuracy: 90.31%\n",
      "Epoch [10] Training Loss: 0.1677, Training Accuracy: 97.89%, Validation Loss: 0.1611, Validation Accuracy: 98.44%\n",
      "Epoch [11] Training Loss: 0.1441, Training Accuracy: 98.12%, Validation Loss: 0.1273, Validation Accuracy: 98.44%\n",
      "Epoch [12] Training Loss: 0.1047, Training Accuracy: 99.06%, Validation Loss: 0.1465, Validation Accuracy: 97.50%\n",
      "Epoch [13] Training Loss: 0.0919, Training Accuracy: 98.83%, Validation Loss: 0.1123, Validation Accuracy: 98.75%\n",
      "Epoch [14] Training Loss: 0.0657, Training Accuracy: 99.30%, Validation Loss: 0.1162, Validation Accuracy: 98.44%\n",
      "Epoch [15] Training Loss: 0.0489, Training Accuracy: 99.38%, Validation Loss: 0.0758, Validation Accuracy: 99.06%\n",
      "Epoch [16] Training Loss: 0.0571, Training Accuracy: 99.30%, Validation Loss: 0.0907, Validation Accuracy: 97.81%\n",
      "Epoch [17] Training Loss: 0.0441, Training Accuracy: 99.53%, Validation Loss: 0.0507, Validation Accuracy: 99.38%\n",
      "Epoch [18] Training Loss: 0.0467, Training Accuracy: 99.45%, Validation Loss: 0.0369, Validation Accuracy: 99.69%\n",
      "Epoch [19] Training Loss: 0.0370, Training Accuracy: 99.53%, Validation Loss: 0.0834, Validation Accuracy: 97.50%\n",
      "Epoch [20] Training Loss: 0.0308, Training Accuracy: 99.69%, Validation Loss: 0.0698, Validation Accuracy: 98.75%\n",
      "Training interrotto manualmente\n"
     ]
    }
   ],
   "source": [
    "model=model.to(dev)\n",
    "best_val_accuracy = 0.0\n",
    "best_val_loss = 0.0\n",
    "epoch = 0\n",
    "\n",
    "#Loop di addestramento(puo essere interrotto)\n",
    "try:\n",
    "    while True:\n",
    "        # Fase di addestramento\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for batch_images, batch_labels in train_loader:\n",
    "            batch_images=transform(batch_images)\n",
    "            batch_images = batch_images.to(\"cuda\")\n",
    "            batch_labels = batch_labels.to(\"cuda\") \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_images)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += batch_labels.size(0)\n",
    "            train_correct += (predicted == batch_labels).sum().item()\n",
    "            train_loss += loss.item() * batch_images.size(0)\n",
    "\n",
    "        train_accuracy = train_correct / train_total\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        # Fase di convalida\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_images, batch_labels in val_loader:\n",
    "                batch_images=transform(batch_images)\n",
    "                batch_images = batch_images.to(\"cuda\")\n",
    "                batch_labels = batch_labels.to(\"cuda\") \n",
    "                outputs = model(batch_images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_loss += criterion(outputs, batch_labels)\n",
    "                val_total += batch_labels.size(0)\n",
    "                val_correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step(val_accuracy)\n",
    "        torch.save(model.state_dict(), \"model_4_\"+str(epoch)+\".pth\")\n",
    "        print(f\"Epoch [{epoch+1}] Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2%}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "        epoch += 1\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrotto manualmente\")\n",
    "    torch.save(model.state_dict(), \"model_4_lastSave.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione che legge un path da un file csv, prende l'immagine associata e ne predice il risultato e lo scrive su un file submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_ev(model_path):\n",
    "    data_transforms = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.CenterCrop(224)\n",
    "    ])\n",
    "    \n",
    "    label_pre=[]\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(\"cuda\")\n",
    "    model.eval()\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    output_file = 'submission.csv'\n",
    "    with open(output_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['image', 'class']) \n",
    "        for i, (image_path, x_min, y_min, x_max, y_max) in test_df.iterrows():\n",
    "            bbox = x_min, y_min, x_max, y_max\n",
    "            image_ = os.path.join('AI/test', image_path.replace('/', '\\\\'))\n",
    "            image = crop(image_,bbox)\n",
    "            image = data_transforms(image)\n",
    "            image = image.float()\n",
    "            image = image.unsqueeze(0)\n",
    "            image = image.cuda()\n",
    "            with torch.no_grad():\n",
    "                outputs = model(image)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                predicted_label = predicted.item()\n",
    "                label_pre.append(predicted_label)\n",
    "                writer.writerow([image_path, predicted_label])\n",
    "    return label_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funziione che ritorna le performance del modello sul test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(label_pre):\n",
    "    class_df = pd.read_csv('class.csv')\n",
    "    i = 0\n",
    "    correct = 0\n",
    "    for label in class_df.iterrows():\n",
    "        if int(label[1].values) == label_pre[i]:\n",
    "            correct = correct + 1\n",
    "        else:\n",
    "            print(i)\n",
    "            \n",
    "        i = i + 1    \n",
    "    return correct/i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'epoca 18 si distingue perché ha una perdita di validazione molto bassa e un'accuratezza di validazione molto alta e non siamo in zona di overfitting.\n",
    "Dopo quest'epoca le prestazioni cominciano a peggiorare.\n",
    "Risultati sui test 99.125%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] Training Loss: 0.0324, Training Accuracy: 99.69%, Validation Loss: 0.0343, Validation Accuracy: 99.38%\n",
      "Epoch [2] Training Loss: 0.0199, Training Accuracy: 99.77%, Validation Loss: 0.0193, Validation Accuracy: 99.69%\n",
      "Epoch [3] Training Loss: 0.0248, Training Accuracy: 99.38%, Validation Loss: 0.0305, Validation Accuracy: 99.06%\n",
      "Epoch [4] Training Loss: 0.0355, Training Accuracy: 98.98%, Validation Loss: 0.0420, Validation Accuracy: 98.75%\n",
      "Epoch [5] Training Loss: 0.0138, Training Accuracy: 99.77%, Validation Loss: 0.0324, Validation Accuracy: 99.38%\n",
      "Training interrotto manualmente\n"
     ]
    }
   ],
   "source": [
    "model_path = 'model_4_17.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model=model.to(dev)\n",
    "# Definizione deela funzione di loss e l'ottimizzatore\n",
    "lr=10e-6\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0)\n",
    "best_val_accuracy = 0.0\n",
    "best_val_loss = 0.0\n",
    "epoch = 0\n",
    "\n",
    "#Loop di addestramento(puo essere interrotto)\n",
    "try:\n",
    "    while True:\n",
    "        # Fase di addestramento\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for batch_images, batch_labels in train_loader:\n",
    "            batch_images=transform(batch_images)\n",
    "            batch_images = batch_images.to(\"cuda\")\n",
    "            batch_labels = batch_labels.to(\"cuda\") \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_images)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += batch_labels.size(0)\n",
    "            train_correct += (predicted == batch_labels).sum().item()\n",
    "            train_loss += loss.item() * batch_images.size(0)\n",
    "\n",
    "        train_accuracy = train_correct / train_total\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        # Fase di convalida\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_images, batch_labels in val_loader:\n",
    "                batch_images=transform(batch_images)\n",
    "                batch_images = batch_images.to(\"cuda\")\n",
    "                batch_labels = batch_labels.to(\"cuda\") \n",
    "                outputs = model(batch_images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_loss += criterion(outputs, batch_labels)\n",
    "                val_total += batch_labels.size(0)\n",
    "                val_correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step(val_accuracy)\n",
    "        torch.save(model.state_dict(), \"model_4.1.\"+str(epoch)+\".pth\")\n",
    "        print(f\"Epoch [{epoch+1}] Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2%}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "        epoch += 1\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrotto manualmente\")\n",
    "    torch.save(model.state_dict(), \"model_4.1_lastSave.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anche qui è facile quale epoca scegliere, la numero 2, 99.75% sul test.Dopo questa epoca il modello comincia a mostrare segni di overfitting.\n",
    "Adesso alleniamo solo il classificatore per vedere se possiamo aumentare ancora le performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] Training Loss: 0.2316, Training Accuracy: 93.98%, Validation Loss: 0.0138, Validation Accuracy: 100.00%\n",
      "Epoch [2] Training Loss: 0.0230, Training Accuracy: 99.38%, Validation Loss: 0.0190, Validation Accuracy: 99.69%\n",
      "Epoch [3] Training Loss: 0.0269, Training Accuracy: 99.61%, Validation Loss: 0.0430, Validation Accuracy: 99.06%\n",
      "Epoch [4] Training Loss: 0.0278, Training Accuracy: 99.61%, Validation Loss: 0.0500, Validation Accuracy: 99.38%\n",
      "Epoch [5] Training Loss: 0.0567, Training Accuracy: 98.67%, Validation Loss: 0.0209, Validation Accuracy: 99.69%\n",
      "Epoch [6] Training Loss: 0.0434, Training Accuracy: 98.98%, Validation Loss: 0.0370, Validation Accuracy: 99.06%\n",
      "Epoch [7] Training Loss: 0.0204, Training Accuracy: 99.84%, Validation Loss: 0.2257, Validation Accuracy: 91.88%\n",
      "Training interrotto manualmente\n"
     ]
    }
   ],
   "source": [
    "model_path = \"model_4.1.1.pth\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(n_inputs, num_classes),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "model=model.to(dev)\n",
    "# Definizione deela funzione di loss e l'ottimizzatore\n",
    "lr=10e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.1)\n",
    "best_val_accuracy = 0.0\n",
    "best_val_loss = 0.0\n",
    "epoch = 0\n",
    "\n",
    "#Loop di addestramento(puo essere interrotto)\n",
    "try:\n",
    "    while True:\n",
    "        # Fase di addestramento\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for batch_images, batch_labels in train_loader:\n",
    "            batch_images=transform(batch_images)\n",
    "            batch_images = batch_images.to(\"cuda\")\n",
    "            batch_labels = batch_labels.to(\"cuda\") \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_images)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += batch_labels.size(0)\n",
    "            train_correct += (predicted == batch_labels).sum().item()\n",
    "            train_loss += loss.item() * batch_images.size(0)\n",
    "\n",
    "        train_accuracy = train_correct / train_total\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        # Fase di convalida\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_images, batch_labels in val_loader:\n",
    "                batch_images=transform(batch_images)\n",
    "                batch_images = batch_images.to(\"cuda\")\n",
    "                batch_labels = batch_labels.to(\"cuda\") \n",
    "                outputs = model(batch_images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_loss += criterion(outputs, batch_labels)\n",
    "                val_total += batch_labels.size(0)\n",
    "                val_correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step(val_accuracy)\n",
    "        torch.save(model.state_dict(), \"model_4.1.\"+str(epoch)+\".pth\")\n",
    "        print(f\"Epoch [{epoch+1}] Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2%}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "        epoch += 1\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrotto manualmente\")\n",
    "    torch.save(model.state_dict(), \"model_4.1_lastSave.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anche qui dopo l'epoca 2 ci sono leggeri segni di overfitting che sono gia chiari dopo l'epoca 5. Risulati sul test 99.875%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99875"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"model_4.1.1.pth\"\n",
    "label_pre=model_ev(model_path)\n",
    "test(label_pre)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
