{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo le librerie necessarie per il progetto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image,ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet152\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recupero il numero delle classi e verifico se la scheda video è impostata come device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n° Classi: 8\n",
      "Numero di canali: 3\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "train_path = r'C:\\Users\\alessio\\Desktop\\Project\\AI\\train'\n",
    "test_path = r'C:\\Users\\alessio\\Desktop\\Project\\AI\\test'\n",
    "image_path = r'C:\\Users\\alessio\\Desktop\\Project\\AI\\train\\01\\01_000.png'\n",
    "image = Image.open(image_path)\n",
    "num_classes = len(os.listdir(train_path))\n",
    "print(\"n° Classi:\", num_classes)\n",
    "num_channels = len(image.getbands())\n",
    "print(\"Numero di canali:\", num_channels)\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa funzione prende in input un percorso relativo ad un'immagine (image_path), una bounding box (bbox) che specifica la regione di interesse dell'immagine e  l'immagine presa col path viene ritagliata in base ai valori della bounding box e normalizzata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(image_path, bbox):\n",
    "    # Estrae le coordinate del bounding box\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "    # Carica l'immagine in formato BGR (Blu, Verde, Rosso)\n",
    "    image_rgb = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # Esegue il ritaglio dell'immagine utilizzando le coordinate del bounding box\n",
    "    cropped_image = image_rgb[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    # Ridimensiona l'immagine ritagliata a una dimensione desiderata (280x280)\n",
    "    resized_image = cv2.resize(cropped_image, (280, 280))\n",
    "\n",
    "    # Normalizza i valori dei pixel nell'intervallo [0, 1]\n",
    "    normalized_image = np.array(resized_image) / 255.0\n",
    "\n",
    "    return normalized_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo codice legge un file CSV contenente informazioni sulle immagini come:path, bounding box e etichette. Successivamente, manda ciascuna immagine in elaborazione alla funzione precedete, dopo memorizza l'immagine elaborata e l'etichetta associata in liste separate per l'addestramento di un modello di machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []  # Lista in cui verranno memorizzate le immagini elaborate\n",
    "train_labels = []  # Lista in cui verranno memorizzate le etichette\n",
    "train_df = pd.read_csv('train.csv')  # Carica i dati di addestramento da un file CSV\n",
    "\n",
    "# Itera su ciascuna riga del DataFrame train_df\n",
    "for i, (imp, x_min, y_min, x_max, y_max, label) in train_df.iterrows():\n",
    "    # Costruisce il percorso completo dell'immagine da caricare\n",
    "    image_path = os.path.join('AI/train', imp.replace('/', '\\\\'))\n",
    "    \n",
    "    # Assicura che le coordinate del bounding box siano non negative\n",
    "    bbox = [x_min, y_min, x_max, y_max]\n",
    "    for i in range(len(bbox)):\n",
    "        if bbox[i] < 0:\n",
    "            bbox[i] = 0\n",
    "\n",
    "    # Chiama la funzione crop per ritagliare e preparare l'immagine\n",
    "    image = crop(image_path, bbox)\n",
    "    \n",
    "    # Costruisce il nuovo percorso completo in cui salvare l'immagine\n",
    "    image_path = os.path.join('AI/save', imp.replace('/', '\\\\'))\n",
    "    \n",
    "    # Ottiene le dimensioni dell'immagine risultante\n",
    "    a, b, c = image.shape\n",
    "    \n",
    "    # Aggiunge l'etichetta e l'immagine alle liste di addestramento\n",
    "    train_labels.append(label)\n",
    "    train_images.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo codice converte le immagini e le etichette del dataset in tensori PyTorch, necessari per l'addestramento di modelli di deep learning. Inoltre, riorganizza le dimensioni delle immagini per adattarle al formato comunemente utilizzato da PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: [0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "train_images = np.array(train_images)  # Converte la lista di immagini in un array NumPy\n",
    "train_labels = np.array(train_labels)  # Converte la lista di etichette in un array NumPy\n",
    "labels = list(set(train_labels))  # Ottiene l'elenco unico delle etichette presenti nei dati di addestramento\n",
    "\n",
    "# Stampa l'elenco delle etichette uniche\n",
    "print(\"labels:\", labels)\n",
    "\n",
    "# Conversione delle immagini in tensori\n",
    "train_images_tensor = torch.from_numpy(train_images).permute(0, 3, 1, 2).float()\n",
    "train_labels_tensor = torch.from_numpy(train_labels).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imposto la batch size e creo il dataset di addestramento, di validazione e i data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.transforms as T\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "batch_size = 32  # Dimensione del batch per i data loader\n",
    "\n",
    "# Divisione dei dati in set di addestramento (train) e di convalida (validation)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(train_images_tensor, train_labels_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creazione dei dataset utilizzando TensorDataset\n",
    "train_dataset = TensorDataset(X_train, Y_train)  # Dataset di addestramento\n",
    "val_dataset = TensorDataset(X_val, Y_val)        # Dataset di convalida\n",
    "\n",
    "# Crea i data loader per l'addestramento e la convalida\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo modello si sulla trasformazione colorjitter, tale trasformazione aiuta il modello a generalizzare meglio poiche va a cambiare i colori all'interno dell'immagine inoltre viene fatto un crop a 224 per eliminare informazioni inutili dall'immagine e perche resnet lavora meglio con queste dimensioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] Training Loss: 1.0292, Training Accuracy: 78.44%, Validation Loss: 0.1884, Validation Accuracy: 96.88%\n",
      "Epoch [2] Training Loss: 0.0607, Training Accuracy: 98.75%, Validation Loss: 0.0263, Validation Accuracy: 99.38%\n",
      "Epoch [3] Training Loss: 0.0299, Training Accuracy: 99.45%, Validation Loss: 0.0892, Validation Accuracy: 97.19%\n",
      "Epoch [4] Training Loss: 0.0113, Training Accuracy: 99.92%, Validation Loss: 0.0222, Validation Accuracy: 99.38%\n",
      "Epoch [5] Training Loss: 0.0131, Training Accuracy: 99.61%, Validation Loss: 0.0148, Validation Accuracy: 99.69%\n",
      "Epoch [6] Training Loss: 0.0079, Training Accuracy: 99.84%, Validation Loss: 0.0474, Validation Accuracy: 98.44%\n",
      "Training interrotto manualmente\n"
     ]
    }
   ],
   "source": [
    "# Caricamento del modello preallenato resnet152\n",
    "from torchvision.models import resnet152\n",
    "model = resnet152(weights=\"IMAGENET1K_V2\")\n",
    "\n",
    "# Definizione delle trasformazioni per il data augmentation\n",
    "transf = T.ColorJitter(brightness=(0.2, 0.8), contrast=(0.2, 0.8), saturation=(1, 2), hue=(-0.5, 0.5))\n",
    "transform = T.Compose([\n",
    "    T.RandomApply(transf, 0.50),   # Applica trasformazioni con probabilità del 50%\n",
    "    T.RandomHorizontalFlip(),     # Riflessione orizzontale casuale\n",
    "    T.CenterCrop(224)             # Ritaglio centrale delle immagini a 224x224 pixel\n",
    "])\n",
    "\n",
    "# Modifica il classificatore finale del modello\n",
    "n_inputs = model.fc.in_features  # Ottiene il numero di feature in input al classificatore\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True   # Scongela i pesi del modello\n",
    "\n",
    "# Sostituisce il classificatore con uno personalizzato\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.2),              # Dropout con probabilità del 20%\n",
    "    nn.Linear(n_inputs, num_classes),  # Classificatore lineare con il numero di classi desiderato\n",
    "    nn.LogSoftmax(dim=1)         # Log-softmax per la classificazione multiclasse\n",
    ")\n",
    "\n",
    "model = model.to(dev)  # Sposta il modello sulla GPU (o su un dispositivo specificato)\n",
    "\n",
    "# Definizione della funzione di loss e dell'ottimizzatore\n",
    "lr = 0.0001  # Tasso di apprendimento\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.001)  # Ottimizzatore Adam con regolarizzazione L2\n",
    "criterion = nn.NLLLoss()  # Funzione di loss: log-likelihood negativa\n",
    "\n",
    "# Definizione del learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.01, patience=5, verbose=True)\n",
    "\n",
    "best_val_accuracy = 0.0\n",
    "best_val_loss = 0.0\n",
    "epoch = 0\n",
    "\n",
    "# Loop di addestramento (può essere interrotto manualmente)\n",
    "try:\n",
    "    while True:\n",
    "        # Fase di addestramento\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for batch_images, batch_labels in train_loader:\n",
    "            batch_images = transform(batch_images)  # Applica le trasformazioni di data augmentation\n",
    "            batch_images = batch_images.to(\"cuda\")  # Sposta le immagini sulla GPU\n",
    "            batch_labels = batch_labels.to(\"cuda\")  # Sposta le etichette sulla GPU\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_images)  # Calcola le previsioni del modello\n",
    "            loss = criterion(outputs, batch_labels)  # Calcola la loss\n",
    "            loss.backward()  # Calcola i gradienti\n",
    "            optimizer.step()  # Esegue un passo di ottimizzazione\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += batch_labels.size(0)\n",
    "            train_correct += (predicted == batch_labels).sum().item()\n",
    "            train_loss += loss.item() * batch_images.size(0)\n",
    "\n",
    "        train_accuracy = train_correct / train_total\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Fase di convalida\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_images, batch_labels in val_loader:\n",
    "                batch_images = transform(batch_images)\n",
    "                batch_images = batch_images.to(\"cuda\")\n",
    "                batch_labels = batch_labels.to(\"cuda\")\n",
    "                outputs = model(batch_images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_loss += criterion(outputs, batch_labels)\n",
    "                val_total += batch_labels.size(0)\n",
    "                val_correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step(val_accuracy)\n",
    "\n",
    "        # Salvataggio dei pesi del modello\n",
    "        torch.save(model.state_dict(), \"model_4_\" + str(epoch) + \".pth\")\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}] Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2%}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "        epoch += 1\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Addestramento interrotto manualmente\")\n",
    "    torch.save(model.state_dict(), \"model_4_lastSave.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo codice legge da un file csv dei path relativi a delle immagini, per ogni immagine predice una label e scrive il risultato in un file csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il file CSV è stato generato con successo.\n"
     ]
    }
   ],
   "source": [
    "# Definisci le trasformazioni per il data augmentation\n",
    "data_transforms = T.Compose([\n",
    "    T.ToTensor(),          # Converte l'immagine in un tensore\n",
    "    T.CenterCrop(224)     # Esegue un ritaglio centrale delle immagini a 224x224 pixel\n",
    "])\n",
    "label_pre = []  # Lista per memorizzare le previsioni\n",
    "model_path = 'model_4_4.pth'  # Percorso del modello allenato\n",
    "model.load_state_dict(torch.load(model_path))  # Carica i pesi del modello allenato\n",
    "model.to(\"cuda\")  # Sposta il modello sulla GPU\n",
    "model.eval()  # Imposta il modello in modalità di valutazione\n",
    "test_df = pd.read_csv('test.csv')  # Carica il dataframe dei dati di test\n",
    "output_file = 'submission.csv'  # Nome del file di output per le previsioni\n",
    "\n",
    "# Apri il file di output per la scrittura\n",
    "with open(output_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['image', 'class'])  # Scrivi l'intestazione del file CSV\n",
    "\n",
    "    for i, (image_path, x_min, y_min, x_max, y_max) in test_df.iterrows():\n",
    "        bbox = x_min, y_min, x_max, y_max  # Estrai le coordinate del bounding box\n",
    "        image_ = os.path.join('AI/test', image_path.replace('/', '\\\\'))  # Costruisci il percorso dell'immagine\n",
    "        image = crop(image_, bbox)  # Esegui il ritaglio dell'immagine\n",
    "        image = data_transforms(image)  # Applica le trasformazioni\n",
    "        image = image.float()  # Converti l'immagine in tipo float\n",
    "        image = image.unsqueeze(0)  # Aggiungi una dimensione batch\n",
    "        image = image.cuda()  # Sposta l'immagine sulla GPU\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(image)  # Calcola le previsioni del modello\n",
    "            _, predicted = torch.max(outputs.data, 1)  # Trova la classe predetta\n",
    "            predicted_label = predicted.item()  # Estrai la classe predetta come valore intero\n",
    "            label_pre.append(predicted_label)  # Aggiungi la classe predetta alla lista\n",
    "            writer.writerow([image_path, predicted_label])  # Scrivi l'immagine e la classe predetta nel file CSV\n",
    "\n",
    "print(\"Il file CSV è stato generato con successo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Codice che testa le performance sulle immagini di test, creato per evitare upload inutili su kaagle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non corrette: 2\n",
      "0.9975\n"
     ]
    }
   ],
   "source": [
    "# Precision test per evitare upload inutili\n",
    "class_df = pd.read_csv('class.csv')  # Carica il dataframe contenente le etichette corrette\n",
    "i = 0  # Inizializza un contatore\n",
    "correct = 0  # Inizializza un contatore per le previsioni corrette\n",
    "\n",
    "# Itera attraverso le etichette corrette e le previsioni\n",
    "for label in class_df.iterrows():\n",
    "    if int(label[1].values) == label_pre[i]:\n",
    "        correct = correct + 1  # Incrementa il conteggio se la previsione è corretta\n",
    "    i = i + 1  # Incrementa il conteggio generale delle etichette\n",
    "\n",
    "# Calcola la percentuale di previsioni corrette\n",
    "accuracy = correct / i\n",
    "\n",
    "print(\"non corrette:\", 800 - correct)  # Stampa il numero di previsioni incorrette\n",
    "print(accuracy)  # Stampa l'accuratezza delle previsioni"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
