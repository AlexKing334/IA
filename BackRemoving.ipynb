{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo le librerie necessarie per il progetto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet101\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recupero il numero delle classi e verifico se la scheda video è impostata come device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n° Classi: 8\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "train_path = r'C:\\Users\\alessio\\Desktop\\Dimarco_Lomonaco_Salemi\\BACKREMOVING\\AI\\train'\n",
    "\n",
    "num_classes = len(os.listdir(train_path))\n",
    "print(\"n° Classi:\", num_classes)\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questa funzione prende in input un percorso relativo ad un'immagine (image_path), una bounding box (bbox) che specifica la regione di interesse dell'immagine, e un valore booleano (noback). Se noback è impostato su 0, la funzione esegue la segmentazione dell'immagine per rimuovere lo sfondo intorno alla bounding box utilizzando l'algoritmo GrabCut. Successivamente, l'immagine risultante viene ritagliata in base ai valori della bounding box e normalizzata. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def crop_image(image_path, bbox, noback):\n",
    "    # Carica l'immagine dal percorso specificato\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Estrai i valori x_min, y_min, x_max e y_max dal bounding box\n",
    "    x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "    # Converte l'immagine da BGR a RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Se noback è False (0), esegui la rimozione dello sfondo\n",
    "    if noback == 0:\n",
    "        # Crea una maschera inizialmente vuota\n",
    "        mask = np.zeros(image_rgb.shape[:2], np.uint8)\n",
    "\n",
    "        # Crea modelli per il background (bgd_model) e il foreground (fgd_model)\n",
    "        bgd_model = np.zeros((1, 65), np.float64)\n",
    "        fgd_model = np.zeros((1, 65), np.float64)\n",
    "\n",
    "        # Definisce un rettangolo che contiene l'oggetto da ritagliare\n",
    "        rectangle = (x_min, y_min, x_max - x_min, y_max - y_min)\n",
    "\n",
    "        # Esegue l'algoritmo di GrabCut per separare l'oggetto dallo sfondo\n",
    "        cv2.grabCut(image_rgb, mask, rectangle, bgd_model, fgd_model, 1, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "        # Crea una maschera per il foreground, dove il foreground è etichettato come 3 o 1\n",
    "        mask_fg = np.where((mask == 3) | (mask == 1), 255, 0).astype('uint8')\n",
    "\n",
    "        # Applica la maschera al'immagine per rimuovere lo sfondo\n",
    "        image_rgb = cv2.bitwise_and(image_rgb, image_rgb, mask=mask_fg)\n",
    "\n",
    "    # Esegue il ritaglio dell'immagine basato sul bounding box\n",
    "    cropped_image = image_rgb[y_min:y_max, x_min:x_max]\n",
    "\n",
    "    # Normalizza i valori dell'immagine dividendoli per 255.0\n",
    "    res = np.array(cropped_image) / 255.0\n",
    "\n",
    "    # Restituisce l'immagine ritagliata e, se necessario, senza sfondo\n",
    "    return res\n",
    "\n",
    "# Chiamata alla funzione\n",
    "# risultato = crop_image(image_path, bbox, noback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo codice legge un file CSV contenente informazioni sulle immagini come:path, bounding box e etichette. Successivamente, manda ciascuna immagine in elaborazione alla funzione precedete, dopo memorizza l'immagine elaborata e l'etichetta associata in liste separate per l'addestramento di un modello di machine learning.\n",
    "Il parametro noback collegato all'etichetta (label) è utilizzato per rimuovere il background solo dalle immagini con la prima etichetta (label 0). Questa strategia è adottata per evitare possibili errori di classificazione delle immagini con questa etichetta durante l'addestramento del modello, poichè le immagini di test hanno il suo stesso sfondo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inizializza due liste vuote per archiviare le immagini di addestramento e le relative etichette.\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "# Leggi i dati di addestramento da un file CSV chiamato 'train.csv' utilizzando pandas e memorizzali in un DataFrame.\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "# Itera su ogni riga del DataFrame 'train_df' per processare i dati di addestramento.\n",
    "for i, (imp, x_min, y_min, x_max, y_max, label) in train_df.iterrows():\n",
    "    # Costruisci il percorso completo dell'immagine utilizzando 'imp' e la directory specificata.\n",
    "    image_path = os.path.join('AI/train', imp.replace('/', '\\\\'))\n",
    "    \n",
    "    # Crea un bounding box (bbox) utilizzando i valori di x_min, y_min, x_max e y_max.\n",
    "    bbox = x_min, y_min, x_max, y_max\n",
    "    \n",
    "    # Chiama la funzione 'crop_image' per ritagliare l'immagine e, se necessario, rimuovere lo sfondo.\n",
    "    image = crop_image(image_path, bbox, label)\n",
    "    \n",
    "    # Verifica che l'immagine ritagliata abbia una dimensione non nulla.\n",
    "    a, b, c = image.shape\n",
    "    \n",
    "    # Se l'immagine ha una dimensione valida (diversa da zero), aggiungi l'etichetta e l'immagine alle liste.\n",
    "    if a != 0 and b != 0 and c != 0:\n",
    "        train_labels.append(label)\n",
    "        train_images.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo codice fa la stessa cosa del precedente, solo che carica le immagini senza sfondo per tutte quelle immagini che hanno label diversa da quella iniziale.\n",
    "La ragione principale di questa elaborazione è compensare la perdita di qualità che alcune immagini hanno subito durante il caricamento precedente. Questo processo aiuta anche ad ampliare il dataset di addestramento. Inoltre, il fatto di rimuovere la prima classe (label 0) dall'algoritmo di elaborazione delle immagini aiuta a evitare che il modello apprenda erroneamente il background, riducendo così il rischio di errori di classificazione causati dallo sfondo delle immagini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leggi i dati di addestramento da un file CSV chiamato 'train.csv' utilizzando pandas e memorizzali in un DataFrame.\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "# Itera su ogni riga del DataFrame 'train_df' per processare i dati di addestramento.\n",
    "for i, (imp, x_min, y_min, x_max, y_max, label) in train_df.iterrows():\n",
    "    # Verifica se il valore dell'etichetta 'label' è diverso da 0.\n",
    "    if label != 0:\n",
    "        # Costruisci il percorso completo dell'immagine utilizzando 'imp' e la directory specificata.\n",
    "        image_path = os.path.join('AI/train', imp.replace('/', '\\\\'))\n",
    "        \n",
    "        # Crea un bounding box (bbox) utilizzando i valori di x_min, y_min, x_max e y_max.\n",
    "        bbox = x_min, y_min, x_max, y_max\n",
    "        \n",
    "        # Chiama la funzione 'crop_image' per ritagliare l'immagine e rimuovere lo sfondo (con noback=0).\n",
    "        image = crop_image(image_path, bbox, 0)\n",
    "        \n",
    "        # Verifica che l'immagine ritagliata abbia una dimensione non nulla.\n",
    "        a, b, c = image.shape\n",
    "        \n",
    "        # Se l'immagine ha una dimensione valida (diversa da zero), aggiungi l'etichetta e l'immagine alle liste.\n",
    "        if a != 0 and b != 0 and c != 0:\n",
    "            train_labels.append(label)\n",
    "            train_images.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questo codice converte le immagini e le etichette del dataset in tensori PyTorch, necessari per l'addestramento di modelli di deep learning. Inoltre, riorganizza le dimensioni delle immagini per adattarle al formato comunemente utilizzato da PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: [0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# Converti le liste 'train_images' e 'train_labels' in array NumPy.\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Trova l'insieme unico di etichette presenti nei dati di addestramento.\n",
    "labels = list(set(train_labels))\n",
    "\n",
    "# Stampa le etichette uniche presenti nei dati.\n",
    "print(\"labels:\", labels)\n",
    "\n",
    "# Conversione delle immagini in tensori PyTorch:\n",
    "# - `train_images` viene convertito in un tensore e la disposizione dei canali dell'immagine viene modificata da NHWC (numero campioni x altezza x larghezza x canali) a NCHW.\n",
    "# - `train_labels` viene convertito in un tensore di tipo `long`.\n",
    "train_images_tensor = torch.from_numpy(train_images).permute(0, 3, 1, 2).float()\n",
    "train_labels_tensor = torch.from_numpy(train_labels).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imposto la batch size e creo il dataset di addestramento, di validazione e i data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione della dimensione del batch\n",
    "batch_size = 32\n",
    "\n",
    "# Divisione dei dati in set di addestramento e set di validazione\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    train_images_tensor, train_labels_tensor, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Creazione dei dataset utilizzando TensorDataset da PyTorch\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "val_dataset = TensorDataset(X_val, Y_val)\n",
    "\n",
    "# Creazione dei data loader per caricare i dati in batch durante l'addestramento\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Creo un modello di classificazione delle immagini basato su ResNet-101. I pesi del modello sono scongelati per consentire l'apprendimento dai dati di addestramento. Il classificatore è sostituito con uno personalizzato per adattarlo al nostro problema di classificazione.\n",
    "La seconda parte è dedicata al training del modello dove viene monitorata l'accuratezza e la perdita sia sui dati di addestramento che di convalida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definizione delle trasformazioni per il data augmentation\n",
    "transform = T.Compose([\n",
    "    T.Resize(224, antialias=None),  # Ridimensiona le immagini a 224x224 pixel\n",
    "    T.RandomHorizontalFlip()  # Applica una trasformazione di flip orizzontale casuale alle immagini\n",
    "])\n",
    "\n",
    "# Caricamento di un modello preallenato ResNet con pesi addestrati su ImageNet\n",
    "model = resnet101(weights=\"IMAGENET1K_V2\")\n",
    "\n",
    "# Modifica il classificatore finale del modello per adattarlo al problema specifico\n",
    "n_inputs = model.fc.in_features  # Ottiene il numero di feature in input al classificatore\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(n_inputs, 2048),  # Aggiunge un layer completamente connesso (fully connected)\n",
    "    nn.BatchNorm1d(2048),  # Aggiunge normalizzazione BatchNorm\n",
    "    nn.ReLU(),  # Aggiunge una funzione di attivazione ReLU\n",
    "    nn.Dropout(0.5),  # Aggiunge dropout con probabilità 0.5 per la regolarizzazione\n",
    "    nn.Linear(2048, 2048),  # Secondo layer completamente connesso\n",
    "    nn.BatchNorm1d(2048),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(2048, num_classes),  # Output layer con il numero di classi desiderato\n",
    "    nn.LogSoftmax(dim=1)  # Applica il logaritmo softmax per ottenere le probabilità delle classi\n",
    ")\n",
    "\n",
    "# Scongela tutti i pesi del modello in modo che possa imparare dai dati di addestramento\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Definizione della funzione di costo per l'addestramento, in questo caso NLLLoss (Negative Log Likelihood Loss)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] Training Loss: 0.4803, Training Accuracy: 86.10%, Validation Loss: 0.0384, Validation Accuracy: 99.00%\n",
      "Epoch [2] Training Loss: 0.0339, Training Accuracy: 99.50%, Validation Loss: 0.0273, Validation Accuracy: 99.33%\n",
      "Epoch [3] Training Loss: 0.0224, Training Accuracy: 99.46%, Validation Loss: 0.0345, Validation Accuracy: 99.17%\n",
      "Epoch [4] Training Loss: 0.0138, Training Accuracy: 99.71%, Validation Loss: 0.0169, Validation Accuracy: 99.33%\n",
      "Epoch [5] Training Loss: 0.0129, Training Accuracy: 99.75%, Validation Loss: 0.0262, Validation Accuracy: 99.17%\n",
      "Epoch [6] Training Loss: 0.0145, Training Accuracy: 99.67%, Validation Loss: 0.0242, Validation Accuracy: 99.33%\n",
      "Epoch [7] Training Loss: 0.0197, Training Accuracy: 99.37%, Validation Loss: 0.0175, Validation Accuracy: 99.17%\n",
      "Epoch [8] Training Loss: 0.0139, Training Accuracy: 99.71%, Validation Loss: 0.0161, Validation Accuracy: 99.33%\n",
      "Epoch [9] Training Loss: 0.0117, Training Accuracy: 99.75%, Validation Loss: 0.0166, Validation Accuracy: 99.33%\n",
      "Epoch [10] Training Loss: 0.0209, Training Accuracy: 99.37%, Validation Loss: 0.0271, Validation Accuracy: 99.33%\n",
      "Training interrotto manualmente\n"
     ]
    }
   ],
   "source": [
    "# Sposta il modello sulla GPU specificata (dev) per l'addestramento\n",
    "model = model.to(dev)\n",
    "\n",
    "# Definizione della funzione di loss e dell'ottimizzatore\n",
    "lr = 0.0001  # Tasso di apprendimento\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)  # Ottimizzatore Adam\n",
    "# Definizione del learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.01)\n",
    "best_val_accuracy = 0.0\n",
    "best_val_loss = 0.0\n",
    "epoch = 0\n",
    "\n",
    "# Loop di addestramento (può essere interrotto manualmente)\n",
    "try:\n",
    "    while True:\n",
    "        # Fase di addestramento\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for batch_images, batch_labels in train_loader:\n",
    "            batch_images = transform(batch_images)  # Applica le trasformazioni alle immagini\n",
    "            batch_images = batch_images.to(\"cuda\")  # Sposta le immagini sulla GPU\n",
    "            batch_labels = batch_labels.to(\"cuda\")  # Sposta le etichette sulla GPU\n",
    "            optimizer.zero_grad()  # Azzera i gradienti\n",
    "            outputs = model(batch_images)  # Passa le immagini attraverso il modello\n",
    "            loss = criterion(outputs, batch_labels)  # Calcola la loss\n",
    "            loss.backward()  # Calcola i gradienti\n",
    "            optimizer.step()  # Esegue l'ottimizzazione, aggiorna i pesi\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += batch_labels.size(0)\n",
    "            train_correct += (predicted == batch_labels).sum().item()\n",
    "            train_loss += loss.item() * batch_images.size(0)\n",
    "\n",
    "        train_accuracy = train_correct / train_total\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Fase di convalida\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_images, batch_labels in val_loader:\n",
    "                batch_images = transform(batch_images)  # Applica le trasformazioni alle immagini\n",
    "                batch_images = batch_images.to(\"cuda\")  # Sposta le immagini sulla GPU\n",
    "                batch_labels = batch_labels.to(\"cuda\")  # Sposta le etichette sulla GPU\n",
    "                outputs = model(batch_images)  # Passa le immagini attraverso il modello\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_loss += criterion(outputs, batch_labels)\n",
    "                val_total += batch_labels.size(0)\n",
    "                val_correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step(val_accuracy)  # Aggiorna il tasso di apprendimento dinamicamente\n",
    "        torch.save(model.state_dict(), \"model_1_\" + str(epoch) + \".pth\")  # Salva il modello\n",
    "        print(f\"Epoch [{epoch+1}] Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2%}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "        epoch += 1\n",
    "        torch.cuda.empty_cache()  # Svuota la cache della GPU per evitare memory leak\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Addestramento interrotto manualmente\")\n",
    "    torch.save(model.state_dict(), \"model_1_lastSave.pth\")  # Salva l'ultimo modello in caso di interruzione manuale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione che legge un path da un file csv, prende l'immagine associata e ne predice il risultato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_ev(model_path):\n",
    "    # Definizione delle trasformazioni per il data pre-processing\n",
    "    data_transforms = T.Compose([\n",
    "        T.ToTensor(),  # Converte l'immagine in un tensore PyTorch\n",
    "        T.Resize(224, antialias=None),  # Ridimensiona l'immagine a 224x224 pixel\n",
    "    ])\n",
    "    \n",
    "    label_pre = []  # Lista per memorizzare le previsioni delle etichette\n",
    "    model.load_state_dict(torch.load(model_path))  # Carica i pesi del modello precedentemente addestrato\n",
    "    model.to(\"cuda\")  # Sposta il modello sulla GPU\n",
    "    model.eval()  # Imposta il modello in modalità di valutazione (senza addestramento)\n",
    "    test_df = pd.read_csv('test.csv')  # Legge il file CSV di dati di test\n",
    "    output_file = 'submission.csv'  # Nome del file di output\n",
    "    with open(output_file, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)  # Creazione di un writer per il file CSV di output\n",
    "        writer.writerow(['image', 'class'])  # Scrive l'intestazione nel file di output\n",
    "\n",
    "        for i, (image_path, x_min, y_min, x_max, y_max) in test_df.iterrows():\n",
    "            bbox = x_min, y_min, x_max, y_max\n",
    "            image_ = os.path.join('AI/test', image_path.replace('/', '\\\\'))  # Costruzione del percorso dell'immagine di test\n",
    "            image = crop_image(image_, bbox, 1)  # Ritaglia l'immagine\n",
    "            image = data_transforms(image)  # Applica le trasformazioni all'immagine\n",
    "            image = image.float()  # Converte il tensore in tipo float\n",
    "            image = image.unsqueeze(0)  # Aggiunge una dimensione per rappresentare il batch (batch size 1)\n",
    "            image = image.cuda()  # Sposta l'immagine sulla GPU\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(image)  # Esegue il modello per ottenere le previsioni\n",
    "                _, predicted = torch.max(outputs.data, 1)  # Trova la classe predetta\n",
    "                predicted_label = predicted.item()  # Estrae l'etichetta predetta come valore intero\n",
    "                label_pre.append(predicted_label)  # Aggiunge l'etichetta predetta alla lista\n",
    "                writer.writerow([image_path, predicted_label])  # Scrive l'immagine e l'etichetta nel file di output\n",
    "\n",
    "    return label_pre  # Restituisce la lista delle etichette previste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione che ritorna la percentuale di accuratezza sul test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(label_pre):\n",
    "    # Carica il file CSV delle classi\n",
    "    class_df = pd.read_csv('class.csv')\n",
    "    \n",
    "    i = 0  # Inizializza un contatore per tenere traccia dell'indice delle etichette previste\n",
    "    correct = 0  # Inizializza un contatore per tenere traccia del numero di previsioni corrette\n",
    "    \n",
    "    # Itera attraverso le righe del file CSV delle classi\n",
    "    for label in class_df.iterrows():\n",
    "        # Confronta l'etichetta reale (da class_df) con l'etichetta prevista (da label_pre)\n",
    "        if int(label[1].values) == label_pre[i]:\n",
    "            correct = correct + 1  # Incrementa il contatore se la previsione è corretta\n",
    "        else:\n",
    "            print(i)  # Stampa l'indice dell'etichetta in caso di previsione errata\n",
    "           \n",
    "        i = i + 1  # Passa all'indice successivo\n",
    "    \n",
    "    # Calcola l'accuratezza (il rapporto tra le previsioni corrette e il totale delle previsioni)\n",
    "    accuracy = correct / i\n",
    "    \n",
    "    return accuracy  # Restituisce l'accuratezza calcolata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prendiamo il modello che ha le migliori performance nella fase precedente, ad occhio si puo vedere che il numero 2, dopo di questa infatti ci sono leggeri segni di overfitting.\n",
    "Sotto si allena il modello scelto con un lr piu basso e aggiunto un fattore di regolarizzazione. Il modello scelto ha ottenuto 99.25% sul test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] Training Loss: 0.0238, Training Accuracy: 99.50%, Validation Loss: 0.0172, Validation Accuracy: 99.58%\n",
      "Epoch [2] Training Loss: 0.0186, Training Accuracy: 99.72%, Validation Loss: 0.0178, Validation Accuracy: 99.58%\n",
      "Epoch [3] Training Loss: 0.0249, Training Accuracy: 99.39%, Validation Loss: 0.0170, Validation Accuracy: 99.58%\n",
      "Epoch [4] Training Loss: 0.0211, Training Accuracy: 99.55%, Validation Loss: 0.0171, Validation Accuracy: 99.58%\n",
      "Epoch [5] Training Loss: 0.0184, Training Accuracy: 99.72%, Validation Loss: 0.0179, Validation Accuracy: 99.58%\n",
      "Epoch [6] Training Loss: 0.0180, Training Accuracy: 99.67%, Validation Loss: 0.0184, Validation Accuracy: 99.58%\n",
      "Epoch [7] Training Loss: 0.0200, Training Accuracy: 99.78%, Validation Loss: 0.0162, Validation Accuracy: 99.58%\n",
      "Epoch [8] Training Loss: 0.0197, Training Accuracy: 99.55%, Validation Loss: 0.0169, Validation Accuracy: 99.58%\n",
      "Epoch [9] Training Loss: 0.0247, Training Accuracy: 99.39%, Validation Loss: 0.0172, Validation Accuracy: 99.58%\n",
      "Epoch [10] Training Loss: 0.0209, Training Accuracy: 99.72%, Validation Loss: 0.0182, Validation Accuracy: 99.58%\n",
      "Training interrotto manualmente\n"
     ]
    }
   ],
   "source": [
    "model_path = 'model_1_1.pth'\n",
    "model.load_state_dict(torch.load(model_path))  # Carica i pesi del modello preaddestrato\n",
    "\n",
    "model = model.to(dev)  # Sposta il modello sulla GPU specificata (dev)\n",
    "\n",
    "# Definizione della funzione di loss e dell'ottimizzatore con un nuovo tasso di apprendimento (lr) e regolarizzazione (weight_decay)\n",
    "lr = 1e-7  # Tasso di apprendimento\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.01)  # Ottimizzatore Adam con regolarizzazione L2 (weight decay)\n",
    "best_val_accuracy = 0.0\n",
    "best_val_loss = 0.0\n",
    "epoch = 0\n",
    "\n",
    "# Loop di addestramento (può essere interrotto manualmente)\n",
    "try:\n",
    "    while True:\n",
    "        # Fase di addestramento\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for batch_images, batch_labels in train_loader:\n",
    "            batch_images = transform(batch_images)  # Applica le trasformazioni alle immagini\n",
    "            batch_images = batch_images.to(\"cuda\")  # Sposta le immagini sulla GPU\n",
    "            batch_labels = batch_labels.to(\"cuda\")  # Sposta le etichette sulla GPU\n",
    "            optimizer.zero_grad()  # Azzera i gradienti\n",
    "            outputs = model(batch_images)  # Passa le immagini attraverso il modello\n",
    "            loss = criterion(outputs, batch_labels)  # Calcola la loss\n",
    "            loss.backward()  # Calcola i gradienti\n",
    "            optimizer.step()  # Esegue l'ottimizzazione\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += batch_labels.size(0)\n",
    "            train_correct += (predicted == batch_labels).sum().item()\n",
    "            train_loss += loss.item() * batch_images.size(0)\n",
    "\n",
    "        train_accuracy = train_correct / train_total\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Fase di convalida\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_images, batch_labels in val_loader:\n",
    "                batch_images = transform(batch_images)  # Applica le trasformazioni alle immagini\n",
    "                batch_images = batch_images.to(\"cuda\")  # Sposta le immagini sulla GPU\n",
    "                batch_labels = batch_labels.to(\"cuda\")  # Sposta le etichette sulla GPU\n",
    "                outputs = model(batch_images)  # Passa le immagini attraverso il modello\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_loss += criterion(outputs, batch_labels)\n",
    "                val_total += batch_labels.size(0)\n",
    "                val_correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step(val_accuracy)  # Aggiorna il tasso di apprendimento dinamicamente\n",
    "        torch.save(model.state_dict(), \"model_1_1_\" + str(epoch) + \".pth\")  # Salva il modello\n",
    "        print(f\"Epoch [{epoch+1}] Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2%}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "        epoch += 1\n",
    "        torch.cuda.empty_cache()  # Svuota la cache della GPU per evitare memory leak\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Addestramento interrotto manualmente\")\n",
    "    torch.save(model.state_dict(), \"model_1.1_lastSave.pth\")  # Salva l'ultimo modello in caso di interruzione manuale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poichè le prestazione sembrano molto simili e non c'è evidenza chiara di overfitting, consideriamo l'epoca 7 come la migliore tra quelle fornite, poiché ha la validation loss più bassa. 99.625 sul test;\n",
    "Diminuiamo ulteriolmente il lr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] Training Loss: 0.0188, Training Accuracy: 99.72%, Validation Loss: 0.0181, Validation Accuracy: 99.58%\n",
      "Epoch [2] Training Loss: 0.0173, Training Accuracy: 99.67%, Validation Loss: 0.0172, Validation Accuracy: 99.58%\n",
      "Epoch [3] Training Loss: 0.0205, Training Accuracy: 99.50%, Validation Loss: 0.0170, Validation Accuracy: 99.58%\n",
      "Epoch [4] Training Loss: 0.0215, Training Accuracy: 99.55%, Validation Loss: 0.0176, Validation Accuracy: 99.58%\n",
      "Epoch [5] Training Loss: 0.0202, Training Accuracy: 99.72%, Validation Loss: 0.0170, Validation Accuracy: 99.58%\n",
      "Epoch [6] Training Loss: 0.0196, Training Accuracy: 99.61%, Validation Loss: 0.0172, Validation Accuracy: 99.58%\n",
      "Epoch [7] Training Loss: 0.0201, Training Accuracy: 99.67%, Validation Loss: 0.0174, Validation Accuracy: 99.58%\n",
      "Epoch [8] Training Loss: 0.0172, Training Accuracy: 99.78%, Validation Loss: 0.0173, Validation Accuracy: 99.58%\n",
      "Epoch [9] Training Loss: 0.0183, Training Accuracy: 99.72%, Validation Loss: 0.0176, Validation Accuracy: 99.58%\n",
      "Epoch [10] Training Loss: 0.0200, Training Accuracy: 99.72%, Validation Loss: 0.0175, Validation Accuracy: 99.58%\n",
      "Training interrotto manualmente\n"
     ]
    }
   ],
   "source": [
    "model_path = 'model_1_1_6.pth'\n",
    "model.load_state_dict(torch.load(model_path))  # Carica i pesi del modello preaddestrato\n",
    "\n",
    "model = model.to(dev)  # Sposta il modello sulla GPU specificata (dev)\n",
    "\n",
    "# Definizione della funzione di loss e dell'ottimizzatore con un nuovo tasso di apprendimento (lr) e regolarizzazione (weight_decay)\n",
    "lr = 1e-10  # Tasso di apprendimento molto basso\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.1)  # Ottimizzatore Adam con regolarizzazione L2 (weight decay)\n",
    "best_val_accuracy = 0.0\n",
    "best_val_loss = 0.0\n",
    "epoch = 0\n",
    "\n",
    "# Loop di addestramento (può essere interrotto manualmente)\n",
    "try:\n",
    "    while True:\n",
    "        # Fase di addestramento\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for batch_images, batch_labels in train_loader:\n",
    "            batch_images = transform(batch_images)  # Applica le trasformazioni alle immagini\n",
    "            batch_images = batch_images.to(\"cuda\")  # Sposta le immagini sulla GPU\n",
    "            batch_labels = batch_labels.to(\"cuda\")  # Sposta le etichette sulla GPU\n",
    "            optimizer.zero_grad()  # Azzera i gradienti\n",
    "            outputs = model(batch_images)  # Passa le immagini attraverso il modello\n",
    "            loss = criterion(outputs, batch_labels)  # Calcola la loss\n",
    "            loss.backward()  # Calcola i gradienti\n",
    "            optimizer.step()  # Esegue l'ottimizzazione\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += batch_labels.size(0)\n",
    "            train_correct += (predicted == batch_labels).sum().item()\n",
    "            train_loss += loss.item() * batch_images.size(0)\n",
    "\n",
    "        train_accuracy = train_correct / train_total\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Fase di convalida\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_images, batch_labels in val_loader:\n",
    "                batch_images = transform(batch_images)  # Applica le trasformazioni alle immagini\n",
    "                batch_images = batch_images.to(\"cuda\")  # Sposta le immagini sulla GPU\n",
    "                batch_labels = batch_labels.to(\"cuda\")  # Sposta le etichette sulla GPU\n",
    "                outputs = model(batch_images)  # Passa le immagini attraverso il modello\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_loss += criterion(outputs, batch_labels)\n",
    "                val_total += batch_labels.size(0)\n",
    "                val_correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step(val_accuracy)  # Aggiorna il tasso di apprendimento dinamicamente\n",
    "        torch.save(model.state_dict(), \"model_1.3.\" + str(epoch) + \".pth\")  # Salva il modello\n",
    "        print(f\"Epoch [{epoch+1}] Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2%}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "        epoch += 1\n",
    "        torch.cuda.empty_cache()  # Svuota la cache della GPU per evitare memory leak\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Addestramento interrotto manualmente\")\n",
    "    torch.save(model.state_dict(), \"model_1.3_lastSave.pth\")  # Salva l'ultimo modello in caso di interruzione manuale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qui la scelta ricadeva tra la 2 e la 5, abbiamo scelto la 2 poichè la differenza tra le loss è minima. 99.75 sul test;\n",
    "Poichè i risultati sono gia buoni teniamo questi pesi e cerchiamo di allenare meglio solo il classificatore per vedere se aumentano le performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1] Training Loss: 1.2966, Training Accuracy: 67.23%, Validation Loss: 0.5596, Validation Accuracy: 99.05%\n",
      "Epoch [2] Training Loss: 0.4530, Training Accuracy: 97.79%, Validation Loss: 0.2154, Validation Accuracy: 99.24%\n",
      "Epoch [3] Training Loss: 0.2376, Training Accuracy: 99.02%, Validation Loss: 0.1364, Validation Accuracy: 99.33%\n",
      "Epoch [4] Training Loss: 0.1829, Training Accuracy: 99.38%, Validation Loss: 0.1017, Validation Accuracy: 99.24%\n",
      "Epoch [5] Training Loss: 0.1362, Training Accuracy: 99.28%, Validation Loss: 0.0845, Validation Accuracy: 99.43%\n",
      "Epoch [6] Training Loss: 0.1056, Training Accuracy: 99.64%, Validation Loss: 0.0753, Validation Accuracy: 99.33%\n",
      "Epoch [7] Training Loss: 0.1027, Training Accuracy: 99.54%, Validation Loss: 0.0641, Validation Accuracy: 99.24%\n",
      "Epoch [8] Training Loss: 0.0900, Training Accuracy: 99.44%, Validation Loss: 0.0583, Validation Accuracy: 99.33%\n",
      "Epoch [9] Training Loss: 0.0819, Training Accuracy: 99.28%, Validation Loss: 0.0495, Validation Accuracy: 99.43%\n",
      "Epoch [10] Training Loss: 0.0689, Training Accuracy: 99.64%, Validation Loss: 0.0498, Validation Accuracy: 99.33%\n",
      "Epoch [11] Training Loss: 0.0645, Training Accuracy: 99.64%, Validation Loss: 0.0465, Validation Accuracy: 99.24%\n",
      "Epoch [12] Training Loss: 0.0628, Training Accuracy: 99.64%, Validation Loss: 0.0411, Validation Accuracy: 99.43%\n",
      "Epoch [13] Training Loss: 0.0562, Training Accuracy: 99.54%, Validation Loss: 0.0394, Validation Accuracy: 99.43%\n",
      "Epoch [14] Training Loss: 0.0505, Training Accuracy: 99.59%, Validation Loss: 0.0377, Validation Accuracy: 99.43%\n",
      "Epoch [15] Training Loss: 0.0534, Training Accuracy: 99.49%, Validation Loss: 0.0379, Validation Accuracy: 99.43%\n",
      "Epoch [16] Training Loss: 0.0457, Training Accuracy: 99.79%, Validation Loss: 0.0326, Validation Accuracy: 99.33%\n",
      "Epoch [17] Training Loss: 0.0456, Training Accuracy: 99.64%, Validation Loss: 0.0336, Validation Accuracy: 99.33%\n",
      "Epoch [18] Training Loss: 0.0468, Training Accuracy: 99.59%, Validation Loss: 0.0316, Validation Accuracy: 99.33%\n",
      "Epoch [19] Training Loss: 0.0396, Training Accuracy: 99.74%, Validation Loss: 0.0284, Validation Accuracy: 99.33%\n",
      "Epoch [20] Training Loss: 0.0374, Training Accuracy: 99.59%, Validation Loss: 0.0284, Validation Accuracy: 99.33%\n",
      "Epoch [21] Training Loss: 0.0321, Training Accuracy: 99.85%, Validation Loss: 0.0267, Validation Accuracy: 99.33%\n",
      "Epoch [22] Training Loss: 0.0276, Training Accuracy: 99.74%, Validation Loss: 0.0282, Validation Accuracy: 99.33%\n",
      "Epoch [23] Training Loss: 0.0338, Training Accuracy: 99.69%, Validation Loss: 0.0260, Validation Accuracy: 99.43%\n",
      "Epoch [24] Training Loss: 0.0271, Training Accuracy: 99.64%, Validation Loss: 0.0270, Validation Accuracy: 99.33%\n",
      "Epoch [25] Training Loss: 0.0285, Training Accuracy: 99.69%, Validation Loss: 0.0273, Validation Accuracy: 99.33%\n",
      "Epoch [26] Training Loss: 0.0243, Training Accuracy: 99.79%, Validation Loss: 0.0249, Validation Accuracy: 99.43%\n",
      "Epoch [27] Training Loss: 0.0310, Training Accuracy: 99.59%, Validation Loss: 0.0235, Validation Accuracy: 99.33%\n",
      "Epoch [28] Training Loss: 0.0244, Training Accuracy: 99.69%, Validation Loss: 0.0230, Validation Accuracy: 99.33%\n",
      "Epoch [29] Training Loss: 0.0244, Training Accuracy: 99.69%, Validation Loss: 0.0229, Validation Accuracy: 99.33%\n",
      "Epoch [30] Training Loss: 0.0275, Training Accuracy: 99.74%, Validation Loss: 0.0228, Validation Accuracy: 99.43%\n",
      "Epoch [31] Training Loss: 0.0220, Training Accuracy: 99.69%, Validation Loss: 0.0224, Validation Accuracy: 99.33%\n",
      "Epoch [32] Training Loss: 0.0199, Training Accuracy: 99.85%, Validation Loss: 0.0216, Validation Accuracy: 99.33%\n",
      "Epoch [33] Training Loss: 0.0224, Training Accuracy: 99.59%, Validation Loss: 0.0231, Validation Accuracy: 99.43%\n",
      "Epoch [34] Training Loss: 0.0165, Training Accuracy: 99.74%, Validation Loss: 0.0250, Validation Accuracy: 99.33%\n",
      "Epoch [35] Training Loss: 0.0165, Training Accuracy: 99.74%, Validation Loss: 0.0226, Validation Accuracy: 99.33%\n",
      "Epoch [36] Training Loss: 0.0186, Training Accuracy: 99.79%, Validation Loss: 0.0237, Validation Accuracy: 99.33%\n",
      "Training interrotto manualmente\n"
     ]
    }
   ],
   "source": [
    "model_path = 'model_1.3.1.pth'\n",
    "model.load_state_dict(torch.load(model_path))  # Carica i pesi del modello preaddestrato\n",
    "\n",
    "# Imposta tutti i parametri del modello come non addestrabili (congelati)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modifica il classificatore finale del modello con un nuovo strato\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(n_inputs, 2048),\n",
    "    nn.BatchNorm1d(2048),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(2048, 2048),\n",
    "    nn.BatchNorm1d(2048),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(2048, num_classes),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "model = model.to(dev)  # Sposta il modello sulla GPU specificata (dev)\n",
    "\n",
    "# Definizione della funzione di loss e dell'ottimizzatore con un nuovo tasso di apprendimento (lr) e regolarizzazione (weight_decay)\n",
    "lr = 1e-5  # Tasso di apprendimento\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.1)  # Ottimizzatore Adam con regolarizzazione L2 (weight decay)\n",
    "best_val_accuracy = 0.0\n",
    "best_val_loss = 0.0\n",
    "epoch = 0\n",
    "\n",
    "# Loop di addestramento (può essere interrotto manualmente)\n",
    "try:\n",
    "    while True:\n",
    "        # Fase di addestramento\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for batch_images, batch_labels in train_loader:\n",
    "            batch_images = transform(batch_images)  # Applica le trasformazioni alle immagini\n",
    "            batch_images = batch_images.to(\"cuda\")  # Sposta le immagini sulla GPU\n",
    "            batch_labels = batch_labels.to(\"cuda\")  # Sposta le etichette sulla GPU\n",
    "            optimizer.zero_grad()  # Azzera i gradienti\n",
    "            outputs = model(batch_images)  # Passa le immagini attraverso il modello\n",
    "            loss = criterion(outputs, batch_labels)  # Calcola la loss\n",
    "            loss.backward()  # Calcola i gradienti\n",
    "            optimizer.step()  # Esegue l'ottimizzazione\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_total += batch_labels.size(0)\n",
    "            train_correct += (predicted == batch_labels).sum().item()\n",
    "            train_loss += loss.item() * batch_images.size(0)\n",
    "\n",
    "        train_accuracy = train_correct / train_total\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Fase di convalida\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_images, batch_labels in val_loader:\n",
    "                batch_images = transform(batch_images)  # Applica le trasformazioni alle immagini\n",
    "                batch_images = batch_images.to(\"cuda\")  # Sposta le immagini sulla GPU\n",
    "                batch_labels = batch_labels.to(\"cuda\")  # Sposta le etichette sulla GPU\n",
    "                outputs = model(batch_images)  # Passa le immagini attraverso il modello\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_loss += criterion(outputs, batch_labels)\n",
    "                val_total += batch_labels.size(0)\n",
    "                val_correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "        scheduler.step(val_accuracy)  # Aggiorna il tasso di apprendimento dinamicamente\n",
    "        torch.save(model.state_dict(), \"model_1.4.\" + str(epoch) + \".pth\")  # Salva il modello\n",
    "        print(f\"Epoch [{epoch+1}] Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2%}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "        epoch += 1\n",
    "        torch.cuda.empty_cache()  # Svuota la cache della GPU per evitare memory leak\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrotto manualmente\")\n",
    "    torch.save(model.state_dict(), \"model_1.4_lastSave.pth\")  # Salva l'ultimo modello in caso di interruzione manuale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Senza ombra di dubbio sembra che la miglio epoca sia la 31 poiche dopo di questa ci sono leggeri segnali di overfitting, testiamola:\n",
    "e creiamo il file submission per il test finale su kaagle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99875"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'model_1.4.30.pth'  # Percorso del modello addestrato da utilizzare per le previsioni\n",
    "label_pre = model_ev(model_path)  # Esegue le previsioni utilizzando il modello\n",
    "\n",
    "# Calcola l'accuratezza dei risultati\n",
    "test_result = test(label_pre)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
